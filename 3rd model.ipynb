{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a6bc67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import misc\n",
    "import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import (Dropout,Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, \n",
    "                          Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D)\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.python.keras.utils import layer_utils\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from pydub import AudioSegment\n",
    "import shutil\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9255cb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in c:\\programdata\\anaconda3\\lib\\site-packages (0.25.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e014e4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = 'blues classical country disco pop hiphop metal reggae rock'\n",
    "genres = genres.split()\n",
    "#for g in genres:\n",
    " # path_audio = os.path.join('C:/Users/ADMIN/Desktop/Blockchain/dataset/Data/audio3sec',f'{g}')\n",
    "  #os.makedirs(path_audio)\n",
    " # path_train = os.path.join('C:/Users/ADMIN/Desktop/Blockchain/dataset/Data/spectrograms3sec/train',f'{g}')\n",
    " # path_test = os.path.join('C:/Users/ADMIN/Desktop/Blockchain/dataset/Data/spectrograms3sec/test',f'{g}')\n",
    "  #os. makedirs(path_train)\n",
    "  #os. makedirs(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82a77920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9000 images belonging to 9 classes.\n",
      "Found 9000 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = \"C:/Users/ZIshnu/Desktop/spectrograms3sec/test\"\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,target_size=(288,432),color_mode=\"rgba\",class_mode='categorical',batch_size=128)\n",
    "\n",
    "validation_dir = \"C:/Users/ZIshnu/Desktop/spectrograms3sec/train\"\n",
    "vali_datagen = ImageDataGenerator(rescale=1./255)\n",
    "vali_generator = vali_datagen.flow_from_directory(validation_dir,target_size=(288,432),color_mode='rgba',class_mode='categorical',batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "556636e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenreModel(input_shape = (288,432,4),classes=9):\n",
    "  \n",
    "  X_input = Input(input_shape)\n",
    "\n",
    "  X = Conv2D(8,kernel_size=(3,3),strides=(1,1))(X_input)\n",
    "  X = BatchNormalization(axis=3)(X)\n",
    "  X = Activation('relu')(X)\n",
    "  X = MaxPooling2D((2,2))(X)\n",
    "  \n",
    "  X = Conv2D(16,kernel_size=(3,3),strides = (1,1))(X)\n",
    "  X = BatchNormalization(axis=3)(X)\n",
    "  X = Activation('relu')(X)\n",
    "  X = MaxPooling2D((2,2))(X)\n",
    "  \n",
    "  X = Conv2D(32,kernel_size=(3,3),strides = (1,1))(X)\n",
    "  X = BatchNormalization(axis=3)(X)\n",
    "  X = Activation('relu')(X)\n",
    "  X = MaxPooling2D((2,2))(X)\n",
    "\n",
    "  X = Conv2D(64,kernel_size=(3,3),strides=(1,1))(X)\n",
    "  X = BatchNormalization(axis=-1)(X)\n",
    "  X = Activation('relu')(X)\n",
    "  X = MaxPooling2D((2,2))(X)\n",
    "  \n",
    "  X = Conv2D(128,kernel_size=(3,3),strides=(1,1))(X)\n",
    "  X = BatchNormalization(axis=-1)(X)\n",
    "  X = Activation('relu')(X)\n",
    "  X = MaxPooling2D((2,2))(X)\n",
    "\n",
    "  \n",
    "  X = Flatten()(X)\n",
    "  X = Dense(classes, activation='softmax', name='fc' + str(classes))(X)\n",
    "\n",
    "  model = Model(inputs=X_input,outputs=X,name='GenreModel')\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c72f0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZIshnu\\AppData\\Local\\Temp/ipykernel_35004/2916766418.py:15: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_generator,epochs=20,validation_data=vali_generator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "71/71 [==============================] - 324s 5s/step - loss: 1.4542 - accuracy: 0.5233 - get_f1: 0.4798 - val_loss: 2.2531 - val_accuracy: 0.2217 - val_get_f1: 0.1834\n",
      "Epoch 2/20\n",
      "71/71 [==============================] - 325s 5s/step - loss: 0.7010 - accuracy: 0.7450 - get_f1: 0.7293 - val_loss: 2.9842 - val_accuracy: 0.2222 - val_get_f1: 0.2231\n",
      "Epoch 3/20\n",
      "71/71 [==============================] - 321s 5s/step - loss: 0.5143 - accuracy: 0.8188 - get_f1: 0.8133 - val_loss: 3.7128 - val_accuracy: 0.2256 - val_get_f1: 0.2238\n",
      "Epoch 4/20\n",
      "71/71 [==============================] - 322s 5s/step - loss: 0.4098 - accuracy: 0.8537 - get_f1: 0.8523 - val_loss: 3.4830 - val_accuracy: 0.2608 - val_get_f1: 0.2594\n",
      "Epoch 5/20\n",
      "71/71 [==============================] - 322s 5s/step - loss: 0.3325 - accuracy: 0.8837 - get_f1: 0.8812 - val_loss: 1.1310 - val_accuracy: 0.5774 - val_get_f1: 0.5627\n",
      "Epoch 6/20\n",
      "71/71 [==============================] - 325s 5s/step - loss: 0.2539 - accuracy: 0.9162 - get_f1: 0.9163 - val_loss: 0.7226 - val_accuracy: 0.7454 - val_get_f1: 0.7395\n",
      "Epoch 7/20\n",
      "71/71 [==============================] - 324s 5s/step - loss: 0.1915 - accuracy: 0.9393 - get_f1: 0.9376 - val_loss: 0.3716 - val_accuracy: 0.8529 - val_get_f1: 0.8538\n",
      "Epoch 8/20\n",
      "71/71 [==============================] - 322s 5s/step - loss: 0.1746 - accuracy: 0.9431 - get_f1: 0.9433 - val_loss: 0.3532 - val_accuracy: 0.8708 - val_get_f1: 0.8684\n",
      "Epoch 9/20\n",
      "71/71 [==============================] - 324s 5s/step - loss: 0.1528 - accuracy: 0.9532 - get_f1: 0.9526 - val_loss: 0.2339 - val_accuracy: 0.9089 - val_get_f1: 0.9063\n",
      "Epoch 10/20\n",
      "71/71 [==============================] - 322s 5s/step - loss: 0.0904 - accuracy: 0.9771 - get_f1: 0.9764 - val_loss: 0.1092 - val_accuracy: 0.9706 - val_get_f1: 0.9701\n",
      "Epoch 11/20\n",
      "71/71 [==============================] - 324s 5s/step - loss: 0.0650 - accuracy: 0.9871 - get_f1: 0.9861 - val_loss: 0.0885 - val_accuracy: 0.9778 - val_get_f1: 0.9773\n",
      "Epoch 12/20\n",
      "71/71 [==============================] - 330s 5s/step - loss: 0.0460 - accuracy: 0.9941 - get_f1: 0.9940 - val_loss: 0.0543 - val_accuracy: 0.9907 - val_get_f1: 0.9900\n",
      "Epoch 13/20\n",
      "71/71 [==============================] - 329s 5s/step - loss: 0.0396 - accuracy: 0.9957 - get_f1: 0.9950 - val_loss: 0.0338 - val_accuracy: 0.9986 - val_get_f1: 0.9986\n",
      "Epoch 14/20\n",
      "71/71 [==============================] - 327s 5s/step - loss: 0.0324 - accuracy: 0.9976 - get_f1: 0.9976 - val_loss: 0.0247 - val_accuracy: 0.9991 - val_get_f1: 0.9990\n",
      "Epoch 15/20\n",
      "71/71 [==============================] - 327s 5s/step - loss: 0.0226 - accuracy: 0.9983 - get_f1: 0.9983 - val_loss: 0.0722 - val_accuracy: 0.9787 - val_get_f1: 0.9780\n",
      "Epoch 16/20\n",
      "71/71 [==============================] - 326s 5s/step - loss: 0.0259 - accuracy: 0.9972 - get_f1: 0.9971 - val_loss: 0.0166 - val_accuracy: 0.9996 - val_get_f1: 0.9996\n",
      "Epoch 17/20\n",
      "71/71 [==============================] - 327s 5s/step - loss: 0.0127 - accuracy: 0.9999 - get_f1: 0.9999 - val_loss: 0.0122 - val_accuracy: 0.9999 - val_get_f1: 0.9999\n",
      "Epoch 18/20\n",
      "71/71 [==============================] - 327s 5s/step - loss: 0.0113 - accuracy: 0.9998 - get_f1: 0.9998 - val_loss: 0.0090 - val_accuracy: 1.0000 - val_get_f1: 1.0000\n",
      "Epoch 19/20\n",
      "71/71 [==============================] - 327s 5s/step - loss: 0.0078 - accuracy: 1.0000 - get_f1: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000 - val_get_f1: 1.0000\n",
      "Epoch 20/20\n",
      "71/71 [==============================] - 327s 5s/step - loss: 0.0076 - accuracy: 1.0000 - get_f1: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000 - val_get_f1: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "  \n",
    "model = GenreModel(input_shape=(288,432,4),classes=9)\n",
    "opt = Adam(learning_rate=0.0005)\n",
    "model.compile(optimizer = opt,loss='categorical_crossentropy',metrics=['accuracy',get_f1]) \n",
    "\n",
    "history = model.fit_generator(train_generator,epochs=20,validation_data=vali_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03980914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"GenreModel\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 288, 432, 4)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 286, 430, 8)       296       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 286, 430, 8)      32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 286, 430, 8)       0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 143, 215, 8)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 141, 213, 16)      1168      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 141, 213, 16)     64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 141, 213, 16)      0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 70, 106, 16)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 68, 104, 32)       4640      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 68, 104, 32)      128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 68, 104, 32)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 34, 52, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 32, 50, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 32, 50, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 32, 50, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 16, 25, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 14, 23, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 14, 23, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 14, 23, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 7, 11, 128)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9856)              0         \n",
      "                                                                 \n",
      " fc9 (Dense)                 (None, 9)                 88713     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 188,161\n",
      "Trainable params: 187,665\n",
      "Non-trainable params: 496\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "494545ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: aiproject.model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('aiproject.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fcb033",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
